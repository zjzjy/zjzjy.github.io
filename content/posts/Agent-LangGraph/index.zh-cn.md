---
weight: 1
title: "LangGraph - Introduction"
subtitle: ""
date: 2025-06-21T10:21:11+08:00
draft: false
author: "June"
authorLink: "https://github.com/zjzjy"
description: ""
images: []
resources:
- name: "featured-image"
  src: "featured-image.jpg"

tags: ['Agent','LangGraph']
categories: ['Agent']
lightgallery: true

hiddenFromHomePage: false
hiddenFromSearch: false

featuredImage: ""
featuredImagePreview: ""

license: '<a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a>'
toc:
  auto: false
---
æœ¬æ–‡æ ¹æ®[Hugging Faceä¸Šçš„Agentè¯¾ç¨‹](https://huggingface.co/learn/agents-course/unit2/langgraph/introduction)ç¼–å†™è€Œæˆï¼ŒåŒ…æ‹¬        ã€‚
åœ¨æœ¬ç« èŠ‚æ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ [LangGraph](https://github.com/langchain-ai/langgraph) æ¡†æž¶æž„å»ºåº”ç”¨ç¨‹åºï¼Œè¯¥æ¡†æž¶æ—¨åœ¨å¸®åŠ©æ‚¨æž„å»ºå’Œåè°ƒå¤æ‚çš„ LLM å·¥ä½œæµç¨‹ã€‚LangGraph æ˜¯ä¸€ä¸ªæ¡†æž¶ï¼Œå®ƒé€šè¿‡ä¸ºæ‚¨æä¾›ä»£ç†æµç¨‹çš„æŽ§åˆ¶å·¥å…·ï¼Œå…è®¸æ‚¨æž„å»ºå¯ç”¨äºŽç”Ÿäº§çš„åº”ç”¨ç¨‹åºã€‚
ç›¸å…³èµ„æºï¼š
- [LangGraph ä»£ç†](https://langchain-ai.github.io/langgraph/) - LangGraph ä»£ç†ç¤ºä¾‹
- [LangChain academy](https://academy.langchain.com/courses/intro-to-langgraph) - Full course on LangGraph from LangChain
# ä»€ä¹ˆæ˜¯LangGraphï¼Œä»€ä¹ˆæ—¶å€™ä½¿ç”¨å®ƒï¼Ÿ
LangGraph æ˜¯ [LangChain](https://www.langchain.com/) å¼€å‘çš„ç”¨äºŽç®¡ç†é›†æˆ LLM çš„åº”ç”¨ç¨‹åºçš„æŽ§åˆ¶æµçš„æ¡†æž¶ã€‚  
**é‚£ä¹ˆï¼ŒLangGraphä¸ŽLangChainæœ‰ä»€ä¹ˆä¸åŒï¼Ÿ**LangChain æä¾›äº†ä¸€ä¸ªæ ‡å‡†æŽ¥å£ï¼Œç”¨äºŽä¸Žæ¨¡åž‹å’Œå…¶ä»–ç»„ä»¶äº¤äº’ï¼Œå¯ç”¨äºŽæ£€ç´¢ã€LLM è°ƒç”¨å’Œå·¥å…·è°ƒç”¨ã€‚LangChain ä¸­çš„ç±»å¯ä»¥åœ¨ LangGraph ä¸­ä½¿ç”¨ï¼Œä½†å¹¶éžå¿…é¡»ä½¿ç”¨ã€‚è¿™äº›åŒ…æ˜¯ä¸åŒçš„ï¼Œå¯ä»¥å•ç‹¬ä½¿ç”¨ï¼Œä½†æœ€ç»ˆï¼Œæ‚¨åœ¨ç½‘ä¸Šæ‰¾åˆ°çš„æ‰€æœ‰èµ„æºéƒ½ä¼šåŒæ—¶ä½¿ç”¨è¿™ä¸¤ä¸ªåŒ…ã€‚  
**ä»€ä¹ˆæ—¶å€™åº”è¯¥ä½¿ç”¨ LangGraphï¼Ÿ**  
å½“ä½ éœ€è¦åšä¸€ä¸ªâ€œæŽ§åˆ¶â€å’Œâ€œè‡ªç”±â€ä¹‹é—´çš„æƒè¡¡ï¼š
- æŽ§åˆ¶ï¼šç¡®ä¿å¯é¢„æµ‹è¡Œä¸ºå¹¶ç»´æŠ¤ã€‚
- è‡ªç”±ï¼šè®©LLMæœ‰æ›´å¤šç©ºé—´åŽ»å‘æŒ¥åˆ›é€ åŠ›ã€‚  
ä¾‹å¦‚ï¼šCodeAgentéžå¸¸è‡ªç”±ï¼Œå¯ä»¥åœ¨å•ä¸ªæ“ä½œæ­¥éª¤ä¸­è°ƒç”¨å¤šä¸ªå·¥å…·ï¼Œåˆ›å»ºè‡ªå·±çš„å·¥å…·ç­‰ç­‰ï¼Œä½†è¿™ç§è¡Œä¸ºå¯èƒ½è®©å®ƒä»¬æ¯”ä½¿ç”¨JSONçš„å¸¸è§„ä»£ç†æ›´éš¾ä»¥é¢„æµ‹å’ŒæŽ§åˆ¶ã€‚  

LangGraphåˆ™å¤„äºŽå¦ä¸€ä¸ªæžç«¯ï¼Œå½“æ‚¨éœ€è¦â€œæŽ§åˆ¶â€agentçš„æ‰§è¡Œæ—¶ï¼Œå°±ä¼šå‘æŒ¥ä½œç”¨ã€‚å®ƒä¸ºæ‚¨æä¾›äº†æž„å»ºéµå¾ªå¯é¢„æµ‹æµç¨‹çš„åº”ç”¨ç¨‹åºçš„å·¥å…·ï¼ŒåŒæ—¶ä»ç„¶å……åˆ†åˆ©ç”¨ LLM çš„å¼ºå¤§åŠŸèƒ½ã€‚ç®€è€Œè¨€ä¹‹ï¼Œå¦‚æžœæ‚¨çš„åº”ç”¨ç¨‹åºæ¶‰åŠ**ä¸€ç³»åˆ—éœ€è¦ä»¥ç‰¹å®šæ–¹å¼åè°ƒçš„æ­¥éª¤ï¼Œå¹¶ä¸”åœ¨æ¯ä¸ªè¿žæŽ¥ç‚¹åšå‡ºå†³ç­–**ï¼Œ é‚£ä¹ˆ LangGraph å¯ä»¥æä¾›æ‚¨æ‰€éœ€çš„ç»“æž„ ã€‚

LangGraph æ“…é•¿çš„å…³é”®åœºæ™¯åŒ…æ‹¬ï¼š
- éœ€è¦æ˜Žç¡®æŽ§åˆ¶æµç¨‹çš„å¤šæ­¥éª¤æŽ¨ç†è¿‡ç¨‹
- éœ€è¦åœ¨æ­¥éª¤ä¹‹é—´ä¿æŒçŠ¶æ€çš„åº”ç”¨ç¨‹åº
- å°†ç¡®å®šæ€§é€»è¾‘ä¸Žäººå·¥æ™ºèƒ½åŠŸèƒ½ç›¸ç»“åˆçš„ç³»ç»Ÿ
- éœ€è¦äººå·¥å¹²é¢„çš„å·¥ä½œæµç¨‹
- å…·æœ‰å¤šä¸ªç»„ä»¶ååŒå·¥ä½œçš„å¤æ‚ä»£ç†æž¶æž„
# LangGraphçš„æž„å»ºæ¨¡å—
LangGraph ä¸­çš„åº”ç”¨ç¨‹åºä»Žå…¥å£ç‚¹å¼€å§‹ï¼Œå¹¶ä¸”æ ¹æ®æ‰§è¡Œæƒ…å†µï¼Œæµç¨‹å¯èƒ½ä¼šè½¬åˆ°ä¸€ä¸ªå‡½æ•°æˆ–å¦ä¸€ä¸ªå‡½æ•°ï¼Œç›´åˆ°åˆ°è¾¾ç»“æŸã€‚
![LangGraphç¤ºæ„å›¾](/assets/images/langgraph_node.png)
## State
Stateæ˜¯ LangGraph çš„æ ¸å¿ƒæ¦‚å¿µã€‚å®ƒä»£è¡¨äº†æµç»åº”ç”¨ç¨‹åºçš„æ‰€æœ‰ä¿¡æ¯ã€‚
```python
from typing_extensions import TypeDict

class State(TyprDict):
  graph_state: str
```
çŠ¶æ€æ˜¯ç”¨æˆ·å®šä¹‰çš„ ï¼Œå› æ­¤å­—æ®µåº”è¯¥ç²¾å¿ƒè®¾è®¡ä»¥åŒ…å«å†³ç­–è¿‡ç¨‹æ‰€éœ€çš„æ‰€æœ‰æ•°æ®ï¼ðŸ’¡ï¼š ä»”ç»†è€ƒè™‘æ‚¨çš„åº”ç”¨ç¨‹åºéœ€è¦åœ¨æ­¥éª¤ä¹‹é—´è·Ÿè¸ªå“ªäº›ä¿¡æ¯ã€‚
## Node
Node æ—¶Pythonå‡½æ•°ã€‚æ¯ä¸ªNodeï¼š
- å°†çŠ¶æ€ä½œä¸ºè¾“å…¥
- æ‰§è¡Œæ“ä½œ
- è¿”å›žçŠ¶æ€æ›´æ–°
```python
def node_1(state):
  print("---Node 1----")
  return {"graph_state": state['graph_state']+"I am"}

def node_2(state):
    print("---Node 2---")
    return {"graph_state": state['graph_state'] +" happy!"}

def node_3(state):
    print("---Node 3---")
    return {"graph_state": state['graph_state'] +" sad!"}
```
Nodeå¯ä»¥åŒ…æ‹¬ä»€ä¹ˆå‘¢ï¼Ÿ
- LLM è°ƒç”¨ ï¼šç”Ÿæˆæ–‡æœ¬æˆ–åšå‡ºå†³ç­–
- å·¥å…·è°ƒç”¨ ï¼šä¸Žå¤–éƒ¨ç³»ç»Ÿäº¤äº’
- æ¡ä»¶é€»è¾‘ ï¼šç¡®å®šä¸‹ä¸€æ­¥
- äººå·¥å¹²é¢„ ï¼šèŽ·å–ç”¨æˆ·è¾“å…¥
æ•´ä¸ªå·¥ä½œæµç¨‹æ‰€éœ€çš„ä¸€äº›Nodeï¼ˆå¦‚ START å’Œ ENDï¼‰ç›´æŽ¥å­˜åœ¨äºŽ langGraph ä¸­ã€‚

## Edge
Edgeè¿žæŽ¥Nodeå¹¶å®šä¹‰å›¾ä¸­çš„å¯èƒ½è·¯å¾„ï¼š
```python
import random
from typing import Literal # Literal ç±»åž‹å…è®¸ä½ æ˜Žç¡®è§„å®šå˜é‡çš„å…·ä½“å¯é€‰å€¼ï¼Œè¿™äº›å€¼å¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€æ•´æ•°ã€å¸ƒå°”å€¼ç­‰ä¸å¯å˜ç±»åž‹ã€‚
def decide_mood(state) -> Literal["node_2", "node_3"]:
    
    # Often, we will use state to decide on the next node to visit
    user_input = state['graph_state'] 
    
    # Here, let's just do a 50 / 50 split between nodes 2, 3
    if random.random() < 0.5:

        # 50% of the time, we return Node 2
        return "node_2"
    
    # 50% of the time, we return Node 3
    return "node_3"
```
Edgeså¯ä»¥æ˜¯ï¼š
- ç›´æŽ¥ ï¼šå§‹ç»ˆä»ŽèŠ‚ç‚¹ A åˆ°èŠ‚ç‚¹ B
- æ¡ä»¶ ï¼šæ ¹æ®å½“å‰çŠ¶æ€é€‰æ‹©ä¸‹ä¸€ä¸ªèŠ‚ç‚¹

## StateGraph
StateGraph æ˜¯ä¿å­˜æ•´ä¸ªä»£ç†å·¥ä½œæµç¨‹çš„å®¹å™¨ï¼š
```python
from IPython.display import Image, display
from langgraph.graph import StaeGraph, START, END

# åˆ›å»ºçŠ¶æ€å›¾å¹¶æ·»åŠ èŠ‚ç‚¹
builder = StateGraph(State)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)

# å®šä¹‰èŠ‚ç‚¹ä¹‹é—´çš„è¿žæŽ¥å…³ç³»ï¼ˆè¾¹ï¼‰
builder.add_edge(START, "node_1")
builder.add_conditional_edges("node_1", decide_mood)
builder.add_edge("node_2", END)
builder.add_edge("node_3", END)

graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))

# è°ƒç”¨
graph.invoke({"graph_state": "Hi, this is Lance."})
# è¾“å‡º
#---Node 1---
#---Node 3---
#{'graph_state': 'Hi, this is Lance. I am sad!'}
```
# æž„å»ºä¸€ä¸ªé‚®ä»¶åŠ©æ‰‹å§ï¼
åœ¨è¿™ä¸€å°èŠ‚ï¼Œæˆ‘ä»¬ä¼šå®žçŽ°Alfredçš„ç”µå­é‚®ä»¶å¤„ç†ç³»ç»Ÿï¼Œä»–éœ€è¦æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
1. é˜…è¯»æ”¶åˆ°çš„ç”µå­é‚®ä»¶
2. å°†å…¶å½’ç±»ä¸ºåžƒåœ¾é‚®ä»¶æˆ–åˆæ³•é‚®ä»¶
3. èµ·è‰å¯¹åˆæ³•ç”µå­é‚®ä»¶çš„åˆæ­¥å›žå¤
4. åœ¨åˆæ³•çš„æƒ…å†µä¸‹å‘éŸ¦æ©å…ˆç”Ÿå‘é€ä¿¡æ¯ï¼ˆä»…æ‰“å°ï¼‰
è¿™æ˜¯æˆ‘ä»¬å°†æž„å»ºçš„å·¥ä½œæµç¨‹ï¼š
![email workflow](/assets/images/langgraph_email.png)
## è®¾ç½®çŽ¯å¢ƒ
```python
pip install langgraph langchain_openai

import os
from typing import TypedDict, List, Dict, Any, Optional
from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
```

## Step 1: Define Our State
ä½¿æ‚¨çš„Stateè¶³å¤Ÿå…¨é¢ä»¥è·Ÿè¸ªæ‰€æœ‰é‡è¦ä¿¡æ¯ï¼Œä½†é¿å…æ·»åŠ ä¸å¿…è¦çš„ç»†èŠ‚ã€‚
```python
class EmailState(TypedDict)
  # The email being processed
  email: Dict[str, Any] # Contains subject, sender, body, etc.

   # Category of the email (inquiry, complaint, etc.)
   email_category: Optional[str]

   # Reason why the email was marked as spam
   spam_reason: Optional[str]

   # Analysis and decisions
   is_spam: Optional[bool]

   # Response generation
   email_draft: Optional[str]

   # Processing metadata
   messages: List[DItc[str, Any]]
```
## Step 2: Define Our Nodes
çŽ°åœ¨æˆ‘ä»¬åˆ›å»ºæž„æˆèŠ‚ç‚¹çš„å¤„ç†å‡½æ•°ï¼Œæƒ³ä¸€æƒ³æˆ‘ä»¬éœ€è¦ä»€ä¹ˆï¼Ÿ
1. å°åŠ©æ‰‹è¦è¯»é‚®ä»¶ï¼Œè¿”å›žlogs: å°åŠ©æ‰‹åœ¨å¤„ç†æ¥è‡ªå‘é€è€…æŸæŸå…³äºŽæŸæŸä¸»é¢˜çš„é‚®ä»¶
2. å°åŠ©æ‰‹è¦åˆ¤æ–­æ˜¯ä¸æ˜¯åžƒåœ¾é‚®ä»¶ï¼Œä»ŽLLMå›žç­”ä¸­æå–is_spamï¼Œreasonï¼Œcategoryã€‚
3. å°åŠ©æ‰‹å¤„ç†åžƒåœ¾é‚®ä»¶
4. å°åŠ©æ‰‹èµ·è‰å›žå¤
5. å°åŠ©æ‰‹å›žå¤æ•´ä¸ªè¿‡ç¨‹
```python
# Initialize LLM
model = ChatOpenAI(temparature=0)

def read_email(state: EmailState):
  """Alfred reads and logs the incoming email"""
  email = state["email"]

  # Here we might do some initial preprocessing
  print(f"Alfred is processing an email from {email['sender']} with subject: {email['subject']}")

  # No state changes needed here
  return {}

def classify_email(state: EmailState):
  """Alfred uses an LLM to determine if the email is spam or legitimate"""
  email = state["email"]

  # prepare our prompt for the LLM
  prompt = f"""
    As Alfred the butler, analyze this email and determine if it is spam or legitimate.
    
    Email:
    From: {email['sender']}
    Subject: {email['subject']}
    Body: {email['body']}
    
    First, determine if this email is spam. If it is spam, explain why.
    If it is legitimate, categorize it (inquiry, complaint, thank you, etc.).
    """

    # call the LLM
    messages = [HumanMessage(content=prompt)]
    response = model.invoke(messages)

    # Simple logic to parse the response (in a real app, you'd want more robust parsing)
    
```
# æž„å»ºä¸€ä¸ªæ–‡ä»¶åˆ†æžagentå§ï¼
